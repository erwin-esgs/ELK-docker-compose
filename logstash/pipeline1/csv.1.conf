input {
  file {
    path => "/usr/share/logstash/pipeline/Dummy50k.1.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  csv {
   skip_header => true
   separator => ";"
   columns => ["Object No", "Longitude", "Latitude"]
  }
  mutate {
     convert => { "Object No" => "integer" }
     convert => { "Longitude" => "float" }
     convert => { "Latitude" => "float" }
     add_field => { "location" => "%{[Latitude]},%{[Longitude]}" }
     remove_field => ["Longitude", "Latitude"]
   }
   #mutate {
   #  convert => {
   #    "location" => "geo_point"
   #  }
   #}
   prune {
     remove_field => [ "event.original" , "message", "host.name", "log.file.path" ]
   }
}

output {
  # Add your output configuration here, for example:
  elasticsearch {
    hosts => ["http://nginx:9200"]
    index => "data_csv"
	#document_type => "mapping_type_1"
    #document_id => "%{my_id}"
    template => "/usr/share/logstash/config/mapping1.json"
    template_name => "mapping1"
    template_overwrite => true
  }
}